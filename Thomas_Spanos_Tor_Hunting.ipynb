{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thspanos/AI-LAb/blob/main/Thomas_Spanos_Tor_Hunting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMYBJpBujxX1",
        "outputId": "7a4d477b-696a-4eaf-d34f-8915c972d547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "#εγκατάσταση πακέτου tensorflow (hhttps://www.tensorflow.org/)\n",
        "!pip install tensorflow\n",
        "#εγκατάσταση πακέτου scikit-learn (https://scikit-learn.org/)\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#εισαγωγή βιβλιοθηκών - πακέτων\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NKteLMvn50yf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path):\n",
        "\n",
        "    # 1) φόρτωση (κόβει το DtypeWarning για mixed types)\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "\n",
        "\n",
        "    # Κωδικοποίηση Label-1 και Label-2 σε 0,1,2,...\n",
        "    df['Label-1_code'], _ = pd.factorize(df['Label-1'])\n",
        "    df['Label-2_code'], _ = pd.factorize(df['Label-2'])\n",
        "\n",
        "    # Στόχος: Label-1_code (Tor κ.λπ.)\n",
        "    TARGET_COL = 'Label-1_code'\n",
        "\n",
        " # 3) επιλέγουμε features: όλα εκτός των label-στηλών\n",
        "    feature_df = df.drop(columns=['Label-1', 'Label-2', TARGET_COL], errors='ignore').copy()\n",
        "\n",
        "    # 4) μετατροπή ΟΛΩΝ των features σε αριθμητικά (ό,τι δεν γίνεται -> NaN)\n",
        "    for col in feature_df.columns:\n",
        "        feature_df[col] = pd.to_numeric(feature_df[col], errors='coerce')\n",
        "\n",
        "    # 5) καθαρισμός inf/-inf -> NaN\n",
        "    feature_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # 6) συμπλήρωση NaN με median ανά στήλη (και αν κάποια στήλη έχει όλα NaN, θα μείνει NaN)\n",
        "    med = feature_df.median(numeric_only=True)\n",
        "    feature_df = feature_df.fillna(med)\n",
        "    # ό,τι απέμεινε NaN (π.χ. στήλη που ήταν εξ ολοκλήρου μη-αριθμητική) -> 0\n",
        "    feature_df = feature_df.fillna(0)\n",
        "\n",
        "    # 7) X, y\n",
        "    X = feature_df.values\n",
        "    y = df[TARGET_COL].values\n",
        "\n",
        "    # 8) (προαιρετικός τελικός καθαρισμός ασφαλείας)\n",
        "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "\n",
        "    #y = df[TARGET_COL].values\n",
        "\n",
        "    # 4) μόνο αριθμητικές στήλες για X\n",
        "    #X_num = df.select_dtypes(include=['number']).copy()\n",
        "\n",
        "   # 5) καθάρισμα: inf/-inf -> NaN, και μετά NaN -> median στήλης\n",
        "    #X_num = X_num.replace([np.inf, -np.inf], np.nan)\n",
        "    #X_num = X_num.fillna(X_num.median(numeric_only=True))\n",
        "\n",
        "    # 6) αφαιρούμε τη στήλη στόχο από τα features\n",
        "    #X = X_num.drop(columns=[TARGET_COL], errors='ignore').values\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "Ju0ccl6nAAbq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#συνάρτηση δημιουργίας και εκπαίδευσης νευρωνικού δικτύου\n",
        "def create_and_train_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    # αύξηση των εξόδων σε 4\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "z9q7Qmp6AMe0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#συνάρτηση αξιολόγησης μοντέλου και εκτύπωσης αποτελέσματων κατηγοριοποίησης\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    accuracy = classification_report(y_test, y_pred, output_dict=True)\n",
        "    return accuracy['accuracy']"
      ],
      "metadata": {
        "id": "atn0PMsyAbss"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#συνάρτηση προσομοίωσης \"λ\" αρχιτεκτονικής με επανεκπαίδευση μετά από πλήθος ροών δεδομένων (streaming lambda architecture with periodic retraining)\n",
        "def simulate_streaming_lambda_architecture(csv_file_path, model, scaler, batch_size=500, retrain_every_batches=800, total_batches=8000):\n",
        "    batch_counter = 0\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    while batch_counter < total_batches:\n",
        "        #φόρτωση συνόλου δεδομένων από csv αρχείο\n",
        "        X, y = load_dataset(csv_file_path)\n",
        "\n",
        "        #τυποποίηση (standardize) δεδομένων\n",
        "        X = scaler.transform(X)\n",
        "\n",
        "        #κατάτμηση δεδομένων σε ροές (batches)\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            batch_counter += 1\n",
        "            X_batch = X[i:i + batch_size]\n",
        "            y_batch = y[i:i + batch_size]\n",
        "\n",
        "            #εκπαίδευση μοντέλου με κάθε ροή δεδομένων\n",
        "            model.train_on_batch(X_batch, y_batch)\n",
        "\n",
        "            #περιοδική εκπαίδευση μοντέλου με όλα τα δεδομένα\n",
        "            if batch_counter % retrain_every_batches == 0:\n",
        "                #τμηματοποίηση δεδομένων σε σύνολα εκπαίδευσης και δοκιμών\n",
        "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "                #επανεκπαίδευση μοντέλου με όλα τα δεδομένα\n",
        "                model = create_and_train_model(X_train.shape[1])\n",
        "                model.fit(X_train, y_train, epochs=5, batch_size=64)  # Train for a few epochs\n",
        "\n",
        "                #αποθήκευση των βαρών (weights) του μοντέλου για μελλοντική επανεκπαίδευση\n",
        "                model.save('model_weights.keras')\n",
        "\n",
        "                #αξιολόγηση του μοντέλου στα σύνολα εκπαίδευσης και δοκιμών\n",
        "                train_accuracy = evaluate_model(model, X_train, y_train)\n",
        "                test_accuracy = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "# --- IPS block\n",
        "       #         y_pred = np.argmax(model.predict(X_test), axis=1)   # (N,)\n",
        "        #        blocked_indices = np.where(y_pred == 2)[0]\n",
        "         #       if blocked_indices.size > 0:\n",
        "          #          print(f\"Blocking {len(blocked_indices)} malicious traffic instances.\")\n",
        "# --- IPS block ---\n",
        "\n",
        "\n",
        "                train_accuracies.append(train_accuracy)\n",
        "                test_accuracies.append(test_accuracy)\n",
        "\n",
        "                print(f\"Batch {batch_counter}, Training Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    #εκτύπωση γραφικής απεικόνισης ακρίβειας μοντέλου\n",
        "    plt.plot(range(1, total_batches+1, retrain_every_batches), train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(range(1, total_batches+1, retrain_every_batches), test_accuracies, label='Test Accuracy')\n",
        "    plt.xlabel('Batch Number')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Test Accuracy Over Batches')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZqB6dkyOAtEH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#θέση αρχείου csv με το σύνολο δεδομένων\n",
        "csv_file_path = 'https://raw.githubusercontent.com/thspanos/AI-LAb/refs/heads/main/Data/DarkNet.csv'"
      ],
      "metadata": {
        "id": "UlnEKorYCoeq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#τυποποίηση (standardize) δεδομένων\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "--1WU5nBDIRb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#φόρτωση συνόλου δεδομένων\n",
        "X, y = load_dataset(csv_file_path)\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Il_iJbHsDKbe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#εκπαίδευση μοντέλου\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "model = create_and_train_model(X_train.shape[1])"
      ],
      "metadata": {
        "id": "SBlnsi6kDMv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab264a2-8835-4c89-c716-bffc7a84f88f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#εκκίνηση προσομοίωσης \"λ\" αρχιτεκτονικής με επανεκπαίδευση μοντέλου\n",
        "simulate_streaming_lambda_architecture(csv_file_path, model, scaler)"
      ],
      "metadata": {
        "id": "Vwtbid-eDPRv",
        "outputId": "52863e14-47cb-4cec-80cd-fd3c4ad6603b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-3706577948.py\", line 2, in <cell line: 0>\n\n  File \"/tmp/ipython-input-1055086913.py\", line 21, in simulate_streaming_lambda_architecture\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 605, in train_on_batch\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 228, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 61, in train_step\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py\", line 2000, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_data_1598]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3706577948.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#εκκίνηση προσομοίωσης \"λ\" αρχιτεκτονικής με επανεκπαίδευση μοντέλου\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimulate_streaming_lambda_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1055086913.py\u001b[0m in \u001b[0;36msimulate_streaming_lambda_architecture\u001b[0;34m(csv_file_path, model, scaler, batch_size, retrain_every_batches, total_batches)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#εκπαίδευση μοντέλου με κάθε ροή δεδομένων\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#περιοδική εκπαίδευση μοντέλου με όλα τα δεδομένα\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 ):\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-3706577948.py\", line 2, in <cell line: 0>\n\n  File \"/tmp/ipython-input-1055086913.py\", line 21, in simulate_streaming_lambda_architecture\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 605, in train_on_batch\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 228, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 61, in train_step\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py\", line 2000, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_data_1598]"
          ]
        }
      ]
    }
  ]
}